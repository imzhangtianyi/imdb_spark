{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('read_textRDD').setMaster('local[*]')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rdd_pos = sc.wholeTextFiles(\"./aclImdb/train/pos\") \n",
    "rdd_neg = sc.wholeTextFiles(\"./aclImdb/train/neg\")\n",
    "df_pos = rdd_pos.toDF()\n",
    "df_neg = rdd_neg.toDF()\n",
    "df_pos = df_pos.toDF('Path', 'Review')\n",
    "df_neg = df_neg.toDF('Path', 'Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df_pos.select(fn.regexp_extract('Path', r'(pos/\\d+_\\d)', 1).\\\n",
    "            alias('id'), 'review')\n",
    "df_neg = df_neg.select(fn.regexp_extract('Path', r'(neg/\\d+_\\d)', 1).\\\n",
    "            alias('id'), 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|total_num|\n",
      "+---------+\n",
      "|    12500|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pos.select(fn.count('*').alias('total_num')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df_pos.withColumn('score', fn.lit(1))\n",
    "df_neg = df_neg.withColumn('score', fn.lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_pos.union(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+\n",
      "|         id|              review|score|\n",
      "+-----------+--------------------+-----+\n",
      "| pos/5525_8|A lot of the prob...|    1|\n",
      "| pos/2923_1|Eddie Murphy real...|    1|\n",
      "|pos/10450_1|It was by acciden...|    1|\n",
      "|pos/10836_1|I thought this mo...|    1|\n",
      "| pos/8180_8|this is an entert...|    1|\n",
      "+-----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = df.orderBy(fn.rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+\n",
      "|         id|              review|score|\n",
      "+-----------+--------------------+-----+\n",
      "|neg/12144_2|Although nothing ...|    0|\n",
      "|  neg/638_2|The Good Earth is...|    0|\n",
      "| neg/4737_3|I loved the first...|    0|\n",
      "|neg/10011_3|This film is abou...|    0|\n",
      "| neg/5659_4|A disappointing e...|    0|\n",
      "| pos/2692_8|I enjoyed a lot w...|    1|\n",
      "|neg/11930_2|Times are tough f...|    0|\n",
      "| pos/4070_1|I know Anime. I'v...|    1|\n",
      "|pos/12109_1|Yaitate!! Japan i...|    1|\n",
      "| pos/2148_1|I always look for...|    1|\n",
      "+-----------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imdb.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer\n",
    "tk = RegexTokenizer().setGaps(False).setPattern('\\\\p{L}+').setInputCol('review').setOutputCol('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = tk.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+--------------------+\n",
      "|         id|              review|score|               words|\n",
      "+-----------+--------------------+-----+--------------------+\n",
      "| pos/5525_8|A lot of the prob...|    1|[a, lot, of, the,...|\n",
      "| pos/2923_1|Eddie Murphy real...|    1|[eddie, murphy, r...|\n",
      "|pos/10450_1|It was by acciden...|    1|[it, was, by, acc...|\n",
      "|pos/10836_1|I thought this mo...|    1|[i, thought, this...|\n",
      "| pos/8180_8|this is an entert...|    1|[this, is, an, en...|\n",
      "+-----------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_words.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from pyspark.ml.feature import StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "sw_filter = StopWordsRemover().setStopWords(stop_words).\\\n",
    "            setCaseSensitive(False).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2000).setInputCol('filtered').setOutputCol('tf')\n",
    "idf = IDF().setInputCol('tf').setOutputCol('tfidf')\n",
    "pipeline_tfidf = Pipeline(stages=[tk, sw_filter, cv, idf]).fit(df_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|         id|              review|score|               words|            filtered|                  tf|               tfidf|\n",
      "+-----------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|neg/12144_2|Although nothing ...|    0|[although, nothin...|[although, nothin...|(2000,[0,1,2,4,11...|(2000,[0,1,2,4,11...|\n",
      "|  neg/638_2|The Good Earth is...|    0|[the, good, earth...|[good, earth, per...|(2000,[2,5,6,17,3...|(2000,[2,5,6,17,3...|\n",
      "| neg/4737_3|I loved the first...|    0|[i, loved, the, f...|[loved, first, az...|(2000,[0,1,13,18,...|(2000,[0,1,13,18,...|\n",
      "|neg/10011_3|This film is abou...|    0|[this, film, is, ...|[film, male, esco...|(2000,[0,2,7,8,13...|(2000,[0,2,7,8,13...|\n",
      "| neg/5659_4|A disappointing e...|    0|[a, disappointing...|[disappointing, e...|(2000,[0,4,7,8,12...|(2000,[0,4,7,8,12...|\n",
      "+-----------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = pipeline_tfidf.transform(df_imdb)\n",
    "tfidf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15123, 7377, 2500]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df, validation_df, testing_df = df_imdb.randomSplit([0.6, 0.3, 0.1], seed=10)\n",
    "[training_df.count(), validation_df.count(), testing_df.count()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('score').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(10).\\\n",
    "    setElasticNetParam(0.)\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[pipeline_tfidf, lr]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     avg(correct)|\n",
      "+-----------------+\n",
      "|0.851565677104514|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline.transform(validation_df).\\\n",
    "    select(fn.expr('float(prediction = score)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|avg(correct)|\n",
      "+------------+\n",
      "|      0.8452|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline.transform(testing_df).\\\n",
    "    select(fn.expr('float(prediction = score)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv('imdbcsv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_csv('imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
